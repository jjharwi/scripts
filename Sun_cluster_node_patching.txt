Evacuate node1

root@fwsunc2:/->clnode evacuate fwsunc2

Verify no resources are running on node1

root@fwsunc2:/->clrg status

=== Cluster Resource Groups ===

Group Name         Node Name      Suspended     Status
----------         ---------      ---------     ------
zones_group_1      fwsunc2        No            Offline
                   fwsunc3        No            Online

zones_group_2      fwsunc2        No            Offline
                   fwsunc3        No            Online

To create an alternate boot environment for the system disk, comment out the zone
entries in /etc/zones/index.

root@fwsunc2:/->vi /etc/zones/index
"/etc/zones/index" 11 lines, 445 characters Copyright 2004 Sun Microsystems, Inc.  All rights reserved.
# Use is subject to license terms.
#
# ident "@(#)zones-index1.2     04/04/01 SMI"
#
# DO NOT EDIT: this file is automatically generated by zoneadm(1M)
# and zonecfg(1M).  Any manual changes will be lost.
#
global:installed:/
#testzone:installed:/zones1/zones/testzone:67508360-86a2-6a3a-bf02-d8069cd83dd8
#testzone2:installed:/zones2/zones/testzone2:3e996619-9ca0-c091-8ac0-cc50f6a7c87b

"/etc/zones/index" 11 lines, 445 characters

root@fwsunc2:/->zoneadm list -cv
  ID NAME             STATUS     PATH                           BRAND    IP    
   0 global           running    /                              native   shared

Create an alternate boot environment, determining the newest kernel revision from
the patch cluster README.

root@fwsunc2:/->cd /opt/patches/10_Recommended
root@fwsunc2:/opt/patches/10_Recommended->grep kernel /etc/README
118833-36  SunOS 5.10: kernel patch
120011-14  SunOS 5.10: kernel patch
127127-11  SunOS 5.10: kernel patch
137137-09  SunOS 5.10: kernel patch
141444-09  SunOS 5.10: kernel patch
.... 
root@fwsunc2:/opt/patches/10_Recommended->lucreate -n s10u7_141444-09
Analyzing system configuration.
Comparing source boot environment <s10u7> file systems with the file 
system(s) you specified for the new boot environment. Determining which 
file systems should be in the new boot environment.
Updating boot environment description database on all BEs.
Updating system configuration files.
Creating configuration for boot environment <s10u7_141444-09>.
Source boot environment is <s10u7>.
Creating boot environment <s10u7_141444-09>.
Cloning file systems from boot environment <s10u7> to create boot environment <s10u7_141444-09>.
Creating snapshot for <rpool/ROOT/s10u7> on <rpool/ROOT/s10u7@s10u7_141444-09>.
Creating clone for <rpool/ROOT/s10u7@s10u7_141444-09> on <rpool/ROOT/s10u7_141444-09>.
Setting canmount=noauto for </> in zone <global> on <rpool/ROOT/ >.
Population of boot environment <s10u7_141444-09> successful.
Creation of boot environment <s10u7_141444-09> successful.

Apply the patch cluster to the ABE.

root@fwsunc2:/opt/patches/10_Recommended->./installcluster -B s10u7_141444-09 --s10cluster

Setup ...


Solaris 10 SPARC Recommended Patch Cluster (2009.10.22)

Application of patches started : 2009.11.09 12:52:52

Applying 120900-04 (  1 of 163) ... skipped
Applying 121133-02 (  2 of 163) ... skipped
.......

Installation of patch set to alternate boot environment complete.

Please remember to activate boot environment s10u7_141444-09 with luactivate(1M)
before rebooting.

Install log files written :
/.alt.s10u7_141444-09/var/sadm/install_data/s10s_rec_cluster_short_2009.11.09_12.52.52.log
/.alt.s10u7_141444-09/var/sadm/install_data/s10s_rec_cluster_verbose_2009.11.09_12.52.52.log

Apply the Sun Cluster patches to the ABE.

root@fwsunc2:/opt/patches/10_Recommended->luupgrade -t -n s10u7_141444-09 -s /opt/patches/cluster

Activate the ABE.

root@fwsunc2:/opt/patches/10_Recommended->export BOOT_MENU_FILE="menu.lst"
root@fwsunc2:/opt/patches/10_Recommended->lustatus
Boot Environment           Is       Active Active    Can    Copy      
Name                       Complete Now    On Reboot Delete Status    
-------------------------- -------- ------ --------- ------ ----------
s10u7                      yes      yes    yes       no     -         
s10u7_141444-09            yes      no     no        yes    -         

root@fwsunc2:/opt/patches/10_Recommended->luactivate s10u7_141444-09
A Live Upgrade Sync operation will be performed on startup of boot environment <s10u7_141444-09>.

root@fwsunc2:/opt/patches/10_Recommended->init 0

Verify all patches were applied without booting into the cluster.

ok boot -x

root@fwsunc2:/->uname -a
SunOS fwsunc2 5.10 Generic_141444-09 sun4v sparc SUNW,T5240
root@fwsunc2:/->svcs -xv
root@fwsunc2:/->init 6

Booting into cluster...

Once node1 has booted, update the /etc/zones index file for moving the zones back to node1 from node2, uncommenting the zones entries, and changing the status to configured.

root@fwsunc2:/->vi /etc/zones/index
"/etc/zones/index" 11 lines, 445 characters Copyright 2004 Sun Microsystems, Inc.  All rights reserved.
# Use is subject to license terms.
#
# ident "@(#)zones-index1.2     04/04/01 SMI"
#
# DO NOT EDIT: this file is automatically generated by zoneadm(1M)
# and zonecfg(1M).  Any manual changes will be lost.
#
global:installed:/
testzone:configured:/zones1/zones/testzone:67508360-86a2-6a3a-bf02-d8069cd83dd8
testzone2:configured:/zones2/zones/testzone2:3e996619-9ca0-c091-8ac0-cc50f6a7c87b

"/etc/zones/index" 11 lines, 445 characters

To remove the zones from Cluster control to preclude them trying to boot when moved back to node1, unmonitor and disable the zone resources.

root@fwsunc2:/->clrs disable testzone-rs
root@fwsunc2:/->clrs disable testzone2-rs
root@fwsunc2:/->clrs unmonitor testzone-rs
root@fwsunc2:/->clrs unmonitor testzone2-rs

The zones will be halted, and can now be manipulated using regular zoneadm/zonecfg commands.

Evacuate node2

root@fwsunc2:/->clnode evacuate fwsunc3

The storage groups will be detached from node2 and attached to node1.

root@fwsunc2:/->clrs status

=== Cluster Resources ===

Resource Name        Node Name      State       Status Message
-------------        ---------      -----       --------------
group_1_storage      fwsunc2        Online      Online
                     fwsunc3        Offline     Offline

testzone-rs          fwsunc2        Online      Offline
                     fwsunc3        Offline     Offline

group_2_storage      fwsunc2        Offline     Offline
                     fwsunc3        Online      Online

testzone2-rs         fwsunc2        Offline     Offline
                     fwsunc3        Online      Offline

Use the upgrade on attach feature of zoneadm to patch the zones.

root@fwsunc2:/->zoneadm -z testzone attach -u
Getting the list of files to remove
Removing 4 files
Add 222 of 224 packagesAdd 223 of 224 packagesAdd 224 of 224 packages
Installation of these packages generated warnings: SUNWgssc SUNWkrbr SUNWsczr SUNWsmbar
Updating editable files
The file </var/sadm/system/logs/update_log> within the zone contains a log of the zone update.

Boot the zone and login to verify patch level.

root@fwsunc2:/->zoneadm -z testzone boot
root@fwsunc2:/->zlogin testzone
[Connected to zone 'testzone' pts/3]
Last login: Wed Nov  4 11:31:13 on pts/2
Sun Microsystems Inc.   SunOS 5.10      Generic January 2005
# uname -a
SunOS testzone 5.10 Generic_141444-09 sun4v sparc SUNW,T5240

Use the zoneadm -z zone attach -u command on all zones, verify, and halt all of them, then place the zones back under Cluster control.

root@fwsunc2:/->clrs enable testzone-rs
root@fwsunc2:/->clrs enable testzone2-rs
root@fwsunc2:/->clrs monitor testzone-rs
root@fwsunc2:/->clrs monitor testzone2-rs

root@fwsunc2:/->clrs status

=== Cluster Resources ===

Resource Name        Node Name      State       Status Message
-------------        ---------      -----       --------------
group_1_storage      fwsunc2        Online      Online
                     fwsunc3        Offline     Offline

testzone-rs          fwsunc2        Online      Online - Service is online.
                     fwsunc3        Offline     Offline

group_2_storage      fwsunc2        Online     	Online
                     fwsunc3        Offline     Offline

testzone2-rs         fwsunc2        Online      Online - Service is online.
                     fwsunc3        Offline     Offline

At this point, node1 and all zones are patched and running normally.  node2 can now be patched in the same manner as node1 and when rebooted into the cluster, all nodes and zones will be running at the same patch level.

